<h1>üì∞ Monitor de noticias</h1>

<p>
  Este repositorio implementa un <strong>pipeline completo para recolectar, procesar y visualizar noticias locales</strong> orientadas realizar seguimiento de medios en Entre R√≠os, Argentina.  
  El proyecto fue creado a modo experimental para aprender web scraping, procesamiento de texto y visualizaci√≥n con R/Shiny.
</p>

<hr />

<h2>üîß Tecnolog√≠as utilizadas</h2>
<ul>
  <li><strong>Python</strong> ‚Äì requests, BeautifulSoup, Selenium, pandas, numpy, scikit‚Äëlearn, sentence-transformers, pysentimiento</li>
  <li><strong>R</strong> ‚Äì Shiny, dplyr, plotly, visNetwork y tidyverse para la app interactiva</li>
  <li><strong>Jupyter Notebooks</strong> para exploraci√≥n, limpieza y an√°lisis</li>
  <li><strong>Selenium + webdriver-manager</strong> para scraping din√°mico</li>
  <li><strong>BERTopic</strong> y <strong>SentenceTransformers</strong> para an√°lisis de temas </li>
</ul>

<hr />

<h2>üìÅ Estructura del proyecto</h2>

<h3><code>documentacion/</code></h3>
<p>
  Carpeta para la documentaci√≥n del proyecto. Contiene un documento <code>protocolo_validacion.docx</code> con pautas de validaci√≥n y metodolog√≠a.
</p>

<h3><code>notebooks/</code></h3>
<p>
  Conjunto de notebooks de desarrollo y experimentaci√≥n:
</p>
<ul>
  <li><strong>00_extraccion.ipynb</strong> ‚Äì prototipo inicial de extracci√≥n manual de noticias.</li>
  <li><strong>00_extracci√≥n_automatizada.ipynb</strong> ‚Äì pruebas de extracci√≥n automatizada.</li>
  <li><strong>01_limpieza.ipynb</strong> ‚Äì rutina de limpieza y normalizaci√≥n de datos.</li>
  <li><strong>02_temas.ipynb</strong> ‚Äì an√°lisis exploratorio de temas con modelos de lenguaje.</li>
  <li><strong>03_candidatos.ipynb</strong> ‚Äì filtrado y an√°lisis de menciones a candidatos.</li>
</ul>

<h3><code>scrapers/</code></h3>
<p>
  Scripts de scraping para distintos medios de Entre R√≠os, con filtros por nombres de candidatos y localidades. Generan archivos CSV en <code>data/raw/</code> con backups incrementales.
</p>
<ul>
  <li><strong>analisisdigital.py</strong> ‚Äì raspador para <em>An√°lisis Digital</em>, con paginaci√≥n y guardado incremental.</li>
  <li><strong>apfdigital.py</strong> ‚Äì raspador completo para APF Digital; combina Selenium para navegar listados y requests para detalles; utiliza fechas de corte y filtros de palabras.</li>
  <li><strong>elonce.py</strong> ‚Äì scraper para el portal Elonce, con scroll automatizado y deduplicaci√≥n:contentReference.</li>
  <li><strong>unodigital.py</strong> ‚Äì scraping sin Selenium para Uno Entre R√≠os, iterando por p√°ginas y extrayendo t√≠tulos, copetes y contenido:contentReference.</li>
  <li><strong>scraper_semanal.py</strong> ‚Äì orquestador semanal que ejecuta todos los scrapers, controla ventanas de fechas y guarda resultados.</li>
  <li><strong>process_week.py</strong> ‚Äì consolida los CSV semanales en hist√≥ricos, construye unificado global y genera tablas para la app Shiny (frecuencias diarias, sentimiento, co‚Äëocurrencias, etc.).</li>
  <li><strong>process_week.py</strong> y <strong>pipeline_limpieza.py</strong> cuentan con funciones para limpieza, deduplicaci√≥n, an√°lisis de sentimiento y construcci√≥n de grafos sem√°nticos usando embeddings.</li>
</ul>

<h3><code>version final app/</code></h3>
<p>
  Contiene la versi√≥n final de la <strong>app interactiva en Shiny</strong> que permite explorar las noticias procesadas. El archivo principal <code>app.R</code> monta una interfaz con visualizaciones interactivas (gr√°ficos de frecuencias diarias, sentimiento, tablas de t√≠tulos, grafo de co‚Äëocurrencias, etc.) y define temas oscuros y helpers de UI.  
  La subcarpeta <code>www/</code> incluye <code>styles.css</code> con la paleta de colores y estilos oscuros personalizados.  
  La carpeta <code>rsconnect/shinyapps.io/</code> almacena metadatos de despliegue a shinyapps.io.
</p>

<h3>Otros archivos</h3>
<ul>
  <li><strong>logs.txt</strong> ‚Äì registro de ejecuci√≥n de los scrapers.</li>
  <li><strong>seguimiento-de-noticias.Rproj</strong> ‚Äì proyecto de RStudio para la app.</li>
  <li><strong>.gitignore</strong> ‚Äì ignora datos crudos, logs y archivos temporales.</li>
</ul>

<hr />

<h2>‚ú® Objetivo</h2>
<p>
  El objetivo fue desarrollar un sistema que permita <strong>monitorear la cobertura medi√°tica de figuras y ciudades clave</strong>, realizando:
</p>
<ul>
  <li>Extracci√≥n automatizada de noticias desde varios portales locales.</li>
  <li>Limpieza, unificaci√≥n y enriquecimiento con an√°lisis de sentimiento.</li>
  <li>Exploraci√≥n de temas y co‚Äëocurrencias mediante modelos de lenguaje.</li>
  <li>Visualizaci√≥n en una app Shiny para consultar frecuencias, sentimientos y conexiones sem√°nticas de manera interactiva.</li>
</ul>

<hr />

<h2>üèÉ C√≥mo usar</h2>
<p>
  Acceso a la app: </br>
<a href = "https://mj8qpg-nicolas-gottig.shinyapps.io/app-monitor-noticias/">Monitor de noticias </a>
</p>
