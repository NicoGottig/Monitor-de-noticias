{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59202812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Procesado analisisdigital.csv: (1561, 6)\n",
      "‚úÖ Procesado apfdigital.csv: (1076, 6)\n",
      "‚úÖ Procesado eldiario.csv: (130, 6)\n",
      "‚úÖ Procesado elheraldo.csv: (289, 6)\n",
      "‚úÖ Procesado elonce.csv: (1099, 6)\n",
      "‚úÖ Procesado unodigital.csv: (2486, 6)\n",
      "\n",
      "‚úÖ Total noticias unificadas: 6641\n",
      "            id_nuevo            medio               fecha  \\\n",
      "0  analisisdigital_0  analisisdigital 2025-07-25 18:19:00   \n",
      "1  analisisdigital_1  analisisdigital 2025-07-25 17:05:00   \n",
      "2  analisisdigital_2  analisisdigital 2025-07-25 16:42:00   \n",
      "3  analisisdigital_3  analisisdigital 2025-07-25 13:39:00   \n",
      "4  analisisdigital_4  analisisdigital 2025-07-25 12:50:00   \n",
      "\n",
      "                                              titulo  \\\n",
      "0  Frigerio analiz√≥ junto a su gabinete medidas p...   \n",
      "1  El Gobierno present√≥ la renovada flota de cole...   \n",
      "2  OSER firm√≥ un convenio con el Colegio de Bioqu...   \n",
      "3  ‚ÄúLo acontecido con las horas TIC en J√≥venes y ...   \n",
      "4  El 2 de agosto comenzar√° el preingreso en la F...   \n",
      "\n",
      "                                           contenido  \\\n",
      "0  El gobernador Rogerio Frigerio encabez√≥ este v...   \n",
      "1  El gobierno provincial present√≥ la nueva flota...   \n",
      "2  La Obra Social de Entre R√≠os (OSER) firm√≥ un c...   \n",
      "3  El director de J√≥venes y Adultos dependiente d...   \n",
      "4  El Preingreso Universitario (PIU) es una propu...   \n",
      "\n",
      "                                              enlace  \n",
      "0  https://www.analisisdigital.com.ar/provinciale...  \n",
      "1  https://www.analisisdigital.com.ar/provinciale...  \n",
      "2  https://www.analisisdigital.com.ar/provinciale...  \n",
      "3  https://www.analisisdigital.com.ar/provinciale...  \n",
      "4  https://www.analisisdigital.com.ar/provinciale...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "OLD_PATH = r\"C:\\Users\\Lenovo\\Documents\\github\\seguimiento-de-noticias\\data\\raw\\old\"\n",
    "archivos = [f for f in os.listdir(OLD_PATH) if f.endswith('.csv') and not f.startswith('~')]\n",
    "CODIFICACIONES = ['utf-8', 'latin1', 'windows-1252']\n",
    "\n",
    "MAPEO_ARCHIVOS = {\n",
    "    'analisisdigital': {\n",
    "        'medio': 'analisisdigital',\n",
    "        'titulo': 'titulo',\n",
    "        'contenido': ['contenido'],\n",
    "        'enlace': 'enlace',\n",
    "        'fecha': 'fecha',\n",
    "        'copete': None,\n",
    "        'descripcion': None,\n",
    "        'id': 'id'\n",
    "    },\n",
    "    'apfdigital': {\n",
    "        'medio': 'apfdigital',\n",
    "        'titulo': 'titulo',\n",
    "        'contenido': ['contenido'],\n",
    "        'enlace': 'url',\n",
    "        'fecha': 'fecha',\n",
    "        'copete': None,\n",
    "        'descripcion': None,\n",
    "        'id': 'id'\n",
    "    },\n",
    "    'eldiario': {\n",
    "        'medio': 'eldiario',\n",
    "        'titulo': 'titulo',\n",
    "        'contenido': ['descripcion'],  # 'contenido' NO est√°, usamos 'descripcion'\n",
    "        'enlace': 'enlace',\n",
    "        'fecha': 'fecha',\n",
    "        'copete': None,\n",
    "        'descripcion': 'descripcion',\n",
    "        'id': 'id'\n",
    "    },\n",
    "    'elheraldo': {\n",
    "        'medio': 'elheraldo',\n",
    "        'titulo': 'titulo',\n",
    "        'contenido': ['copete', 'contenido'],\n",
    "        'enlace': 'enlace',\n",
    "        'fecha': 'fecha',\n",
    "        'copete': 'copete',\n",
    "        'descripcion': None,\n",
    "        'id': 'id'\n",
    "    },\n",
    "    'elonce': {\n",
    "        'medio': 'elonce',\n",
    "        'titulo': 'titulo',\n",
    "        'contenido': ['contenido'],\n",
    "        'enlace': 'url',\n",
    "        'fecha': 'fecha',\n",
    "        'copete': None,\n",
    "        'descripcion': None,\n",
    "        'id': 'id'\n",
    "    },\n",
    "    'unodigital': {\n",
    "        'medio': 'unodigital',\n",
    "        # Tomamos 'titulo_x' si est√°, si no 'titulo_y'\n",
    "        'titulo': ['titulo_x', 'titulo_y'],\n",
    "        'contenido': ['contenido'],\n",
    "        'enlace': 'enlace',\n",
    "        'fecha': 'fecha',\n",
    "        'copete': None,\n",
    "        'descripcion': None,\n",
    "        'id': 'id'\n",
    "    }\n",
    "}\n",
    "\n",
    "def cargar_csv_multi_encoding(path, codificaciones):\n",
    "    for cod in codificaciones:\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=cod)\n",
    "        except Exception:\n",
    "            continue\n",
    "    print(f\"‚ùå No se pudo cargar {os.path.basename(path)} con ninguna codificaci√≥n.\")\n",
    "    return None\n",
    "\n",
    "def parse_fecha_flexible(fecha):\n",
    "    if pd.isnull(fecha): return np.nan\n",
    "    for fmt in (\"%Y-%m-%d\", \"%Y-%m-%d %H:%M\", \"%d/%m/%Y\"):\n",
    "        try:\n",
    "            return pd.to_datetime(fecha, format=fmt)\n",
    "        except: continue\n",
    "    return pd.to_datetime(fecha, errors='coerce')\n",
    "\n",
    "dfs = []\n",
    "for archivo in archivos:\n",
    "    archivo_nombre = archivo.replace('.csv', '').lower()\n",
    "    config = MAPEO_ARCHIVOS.get(archivo_nombre)\n",
    "    if config is None:\n",
    "        print(f\"‚ö†Ô∏è Archivo {archivo} no est√° en el dict de mapeo, se saltea.\")\n",
    "        continue\n",
    "    path = os.path.join(OLD_PATH, archivo)\n",
    "    df = cargar_csv_multi_encoding(path, CODIFICACIONES)\n",
    "    if df is not None:\n",
    "        df = df.copy()\n",
    "        df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "        # Titulo: buscar el primero que exista\n",
    "        if isinstance(config['titulo'], list):\n",
    "            for col in config['titulo']:\n",
    "                if col in df.columns:\n",
    "                    titulo = df[col]\n",
    "                    break\n",
    "            else:\n",
    "                titulo = pd.NA\n",
    "        else:\n",
    "            titulo = df[config['titulo']] if config['titulo'] in df.columns else pd.NA\n",
    "\n",
    "        # Contenido: concatenar todas las columnas que correspondan\n",
    "        contenido_cols = [col for col in config['contenido'] if col and col in df.columns]\n",
    "        contenido = df[contenido_cols].fillna('').astype(str).agg(' '.join, axis=1) if contenido_cols else pd.Series(['']*len(df))\n",
    "        \n",
    "        # Si hay copete o descripcion, agregamos (s√≥lo si existen)\n",
    "        if config.get('copete') and config['copete'] in df.columns:\n",
    "            contenido = df[config['copete']].fillna('') + '. ' + contenido\n",
    "        if config.get('descripcion') and config['descripcion'] in df.columns:\n",
    "            contenido = df[config['descripcion']].fillna('') + '. ' + contenido\n",
    "\n",
    "        # Enlace\n",
    "        enlace = df[config['enlace']] if config['enlace'] in df.columns else pd.NA\n",
    "\n",
    "        # Fecha\n",
    "        fecha = df[config['fecha']].apply(parse_fecha_flexible) if config['fecha'] in df.columns else pd.NaT\n",
    "\n",
    "        # Medio\n",
    "        medio = config['medio']\n",
    "\n",
    "        # ID (generar uno nuevo por seguridad)\n",
    "        id_nuevo = [f\"{medio}_{i}\" for i in range(len(df))]\n",
    "\n",
    "        # Construir df final de este archivo\n",
    "        df_final = pd.DataFrame({\n",
    "            'id_nuevo': id_nuevo,\n",
    "            'medio': medio,\n",
    "            'fecha': fecha,\n",
    "            'titulo': titulo,\n",
    "            'contenido': contenido,\n",
    "            'enlace': enlace\n",
    "        })\n",
    "\n",
    "        dfs.append(df_final)\n",
    "        print(f\"‚úÖ Procesado {archivo}: {df_final.shape}\")\n",
    "\n",
    "# Concatenar todo y deduplicar por enlace\n",
    "noticias = pd.concat(dfs, ignore_index=True)\n",
    "noticias = noticias.drop_duplicates(subset='enlace')\n",
    "\n",
    "print(f\"\\n‚úÖ Total noticias unificadas: {len(noticias)}\")\n",
    "print(noticias.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7fe41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèôÔ∏è Noticias con localidad (ciudad) etiquetada: 1828\n",
      "üîé Ranking de noticias por ciudad m√°s nombrada:\n",
      "localidadMasNombrada\n",
      "Paran√°                                                                                1128\n",
      "Concordia                                                                              231\n",
      "Gualeguaych√∫                                                                           109\n",
      "Concepci√≥n del Uruguay                                                                  81\n",
      "Villaguay                                                                               64\n",
      "Paran√° / Concordia                                                                      33\n",
      "Gualeguay                                                                               28\n",
      "Paran√° / Gualeguaych√∫                                                                   18\n",
      "Paran√° / Villaguay                                                                      18\n",
      "Paran√° / Concepci√≥n del Uruguay                                                         15\n",
      "Paran√° / Concordia / Gualeguaych√∫                                                       12\n",
      "Concordia / Gualeguaych√∫                                                                 9\n",
      "Paran√° / Gualeguaych√∫ / Villaguay                                                        7\n",
      "Concordia / Villaguay                                                                    7\n",
      "Paran√° / Concordia / Gualeguaych√∫ / Concepci√≥n del Uruguay                               6\n",
      "Paran√° / Concordia / Gualeguaych√∫ / Gualeguay / Villaguay                                5\n",
      "Concordia / Concepci√≥n del Uruguay                                                       5\n",
      "Gualeguaych√∫ / Gualeguay / Villaguay                                                     5\n",
      "Paran√° / Gualeguay                                                                       5\n",
      "Gualeguaych√∫ / Villaguay                                                                 5\n",
      "Paran√° / Gualeguaych√∫ / Gualeguay / Villaguay                                            4\n",
      "Paran√° / Concordia / Gualeguaych√∫ / Concepci√≥n del Uruguay / Gualeguay / Villaguay       4\n",
      "Paran√° / Concordia / Concepci√≥n del Uruguay                                              4\n",
      "Concordia / Gualeguaych√∫ / Concepci√≥n del Uruguay                                        4\n",
      "Paran√° / Concordia / Villaguay                                                           3\n",
      "Gualeguaych√∫ / Gualeguay                                                                 2\n",
      "Gualeguaych√∫ / Concepci√≥n del Uruguay                                                    2\n",
      "Concepci√≥n del Uruguay / Gualeguay                                                       2\n",
      "Concordia / Gualeguay                                                                    2\n",
      "Gualeguaych√∫ / Concepci√≥n del Uruguay / Gualeguay                                        1\n",
      "Paran√° / Concepci√≥n del Uruguay / Villaguay                                              1\n",
      "Gualeguay / Villaguay                                                                    1\n",
      "Concepci√≥n del Uruguay / Villaguay                                                       1\n",
      "Paran√° / Concepci√≥n del Uruguay / Gualeguay                                              1\n",
      "Gualeguaych√∫ / Concepci√≥n del Uruguay / Villaguay                                        1\n",
      "Concordia / Gualeguaych√∫ / Gualeguay                                                     1\n",
      "Paran√° / Concordia / Gualeguay                                                           1\n",
      "Concordia / Gualeguay / Villaguay                                                        1\n",
      "Concordia / Concepci√≥n del Uruguay / Gualeguay                                           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üßë‚Äçüíº Noticias con intendente etiquetado: 583\n",
      "üîé Ranking de noticias por intendente m√°s nombrado:\n",
      "intendenteMasNombrado\n",
      "Rosario Romero                            450\n",
      "Francisco Azcu√©                            69\n",
      "Mauricio Davico                            25\n",
      "Jos√© Eduardo Lauritto                      17\n",
      "Rosario Romero / Jos√© Eduardo Lauritto     12\n",
      "Dora Bogdan                                 5\n",
      "Claudia Monjo                               5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clasificar palabras clave\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Diccionario con nombres y apellidos ---\n",
    "intendente_info = [\n",
    "    {\"apellido\": \"Romero\",    \"nombres\": [\"Rosario\"],        \"full\": \"Rosario Romero\"},\n",
    "    {\"apellido\": \"Azcu√©\",     \"nombres\": [\"Francisco\"],      \"full\": \"Francisco Azcu√©\"},\n",
    "    {\"apellido\": \"Davico\",    \"nombres\": [\"Mauricio\"],       \"full\": \"Mauricio Davico\"},\n",
    "    {\"apellido\": \"Lauritto\",  \"nombres\": [\"Jos√©\", \"Eduardo\"],\"full\": \"Jos√© Eduardo Lauritto\"},\n",
    "    {\"apellido\": \"Bogdan\",    \"nombres\": [\"Dora\"],           \"full\": \"Dora Bogdan\"},\n",
    "    {\"apellido\": \"Monjo\",     \"nombres\": [\"Claudia\"],        \"full\": \"Claudia Monjo\"},\n",
    "]\n",
    "\n",
    "# --- Palabras a excluir antes (contexto de calle, avenida, barrio) ---\n",
    "exclusiones_espaciales = [\"calle\", \"avenida\", \"barrio\"]\n",
    "\n",
    "def es_mencion_valida(texto, apellido, nombres):\n",
    "    \"\"\"\n",
    "    Eval√∫a si hay menci√≥n v√°lida al intendente por apellido.\n",
    "    \"\"\"\n",
    "    if pd.isnull(texto): return 0\n",
    "\n",
    "    texto = str(texto)\n",
    "    m = 0\n",
    "\n",
    "    # 1. Chequear \"intendente/a + apellido\"\n",
    "    if re.search(rf\"(intendente|intendenta)\\s+{apellido}\", texto, re.IGNORECASE):\n",
    "        m += 5  # peso alto\n",
    "\n",
    "    # 2. Chequear nombre completo (cualquiera de los nombres + apellido)\n",
    "    for nombre in nombres:\n",
    "        if re.search(rf\"{nombre}\\s+{apellido}\", texto, re.IGNORECASE):\n",
    "            m += 3\n",
    "\n",
    "    # 3. Chequear solo apellido (con reglas de exclusi√≥n)\n",
    "    # Buscamos todas las posiciones del apellido en el texto\n",
    "    for match in re.finditer(rf\"\\b{apellido}\\b\", texto, re.IGNORECASE):\n",
    "        idx = match.start()\n",
    "        # Obtener las palabras antes y despu√©s\n",
    "        antes = texto[:idx].split()\n",
    "        despues = texto[match.end():].split()\n",
    "        palabra_antes = antes[-1] if antes else ''\n",
    "        palabra_despues = despues[0] if despues else ''\n",
    "\n",
    "        # a) Palabra anterior es exclusi√≥n espacial\n",
    "        if palabra_antes.lower() in exclusiones_espaciales:\n",
    "            continue\n",
    "        # b) Palabra anterior o siguiente es may√∫scula, ‚â•4 letras, y NO es nombre permitido\n",
    "        if (len(palabra_antes) >= 4 and palabra_antes[0].isupper() and palabra_antes not in nombres):\n",
    "            continue\n",
    "        if (len(palabra_despues) >= 4 and palabra_despues[0].isupper() and palabra_despues not in nombres):\n",
    "            continue\n",
    "        # Si pasa los filtros, suma menci√≥n\n",
    "        m += 1\n",
    "    return m\n",
    "\n",
    "def detectar_intendente(texto):\n",
    "    # Aplica a cada intendente y devuelve el de mayor puntaje de menci√≥n v√°lida\n",
    "    menciones = {info['full']: es_mencion_valida(texto, info['apellido'], info['nombres']) for info in intendente_info}\n",
    "    max_m = max(menciones.values())\n",
    "    if max_m == 0:\n",
    "        return np.nan\n",
    "    # Si hay empate, devuelve todos separados por /\n",
    "    mas_nom = [k for k, v in menciones.items() if v == max_m]\n",
    "    return \" / \".join(mas_nom)\n",
    "\n",
    "# --- Aplicar al dataframe de noticias ---\n",
    "noticias['intendenteMasNombrado'] = noticias['contenido'].apply(detectar_intendente)\n",
    "\n",
    "import re\n",
    "\n",
    "# Lista de localidades\n",
    "localidades = [\n",
    "    'Paran√°', 'Concordia', 'Gualeguaych√∫', 'Concepci√≥n del Uruguay', 'Gualeguay', 'Villaguay'\n",
    "]\n",
    "exclusiones_espaciales = [\"calle\", \"avenida\", \"barrio\"]\n",
    "\n",
    "def es_mencion_valida_localidad(texto, localidad):\n",
    "    \"\"\"\n",
    "    Retorna True si la menci√≥n de localidad es v√°lida (no est√° precedida por calle/avenida/barrio)\n",
    "    \"\"\"\n",
    "    if pd.isnull(texto): return 0\n",
    "    texto = str(texto)\n",
    "    contador = 0\n",
    "    for match in re.finditer(rf\"\\b{re.escape(localidad)}\\b\", texto, re.IGNORECASE):\n",
    "        idx = match.start()\n",
    "        antes = texto[:idx].split()\n",
    "        palabra_antes = antes[-1] if antes else ''\n",
    "        # Excluir si est√° precedida por \"calle\", \"avenida\" o \"barrio\"\n",
    "        if palabra_antes.lower() in exclusiones_espaciales:\n",
    "            continue\n",
    "        contador += 1\n",
    "    return contador\n",
    "\n",
    "def detectar_localidad(texto):\n",
    "    menciones = {loc: es_mencion_valida_localidad(texto, loc) for loc in localidades}\n",
    "    max_m = max(menciones.values())\n",
    "    if max_m == 0:\n",
    "        return np.nan\n",
    "    mas_nom = [k for k, v in menciones.items() if v == max_m]\n",
    "    return \" / \".join(mas_nom)\n",
    "\n",
    "# --- Aplicar al DataFrame ---\n",
    "noticias['localidadMasNombrada'] = noticias['contenido'].apply(detectar_localidad)\n",
    "\n",
    "# -- Cantidad de noticias con localidad (ciudad) etiquetada --\n",
    "if 'localidadMasNombrada' in noticias.columns:\n",
    "    total_ciudad = noticias['localidadMasNombrada'].notna().sum()\n",
    "    print(f\"üèôÔ∏è Noticias con localidad (ciudad) etiquetada: {total_ciudad}\")\n",
    "    print(\"üîé Ranking de noticias por ciudad m√°s nombrada:\")\n",
    "    print(noticias['localidadMasNombrada'].value_counts(dropna=True))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No existe columna 'localidadMasNombrada'.\")\n",
    "\n",
    "# -- Cantidad de noticias con intendente etiquetado --\n",
    "if 'intendenteMasNombrado' in noticias.columns:\n",
    "    total_intendente = noticias['intendenteMasNombrado'].notna().sum()\n",
    "    print(f\"\\nüßë‚Äçüíº Noticias con intendente etiquetado: {total_intendente}\")\n",
    "    print(\"üîé Ranking de noticias por intendente m√°s nombrado:\")\n",
    "    print(noticias['intendenteMasNombrado'].value_counts(dropna=True))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No existe columna 'intendenteMasNombrado'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c40b187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Total de menciones (oraciones): 85836\n",
      "          id_noticia            medio               fecha  \\\n",
      "0  analisisdigital_0  analisisdigital 2025-07-25 18:19:00   \n",
      "1  analisisdigital_0  analisisdigital 2025-07-25 18:19:00   \n",
      "2  analisisdigital_0  analisisdigital 2025-07-25 18:19:00   \n",
      "3  analisisdigital_0  analisisdigital 2025-07-25 18:19:00   \n",
      "4  analisisdigital_0  analisisdigital 2025-07-25 18:19:00   \n",
      "5  analisisdigital_0  analisisdigital 2025-07-25 18:19:00   \n",
      "6  analisisdigital_0  analisisdigital 2025-07-25 18:19:00   \n",
      "7  analisisdigital_0  analisisdigital 2025-07-25 18:19:00   \n",
      "8  analisisdigital_0  analisisdigital 2025-07-25 18:19:00   \n",
      "9  analisisdigital_0  analisisdigital 2025-07-25 18:19:00   \n",
      "\n",
      "                                              titulo  \\\n",
      "0  Frigerio analiz√≥ junto a su gabinete medidas p...   \n",
      "1  Frigerio analiz√≥ junto a su gabinete medidas p...   \n",
      "2  Frigerio analiz√≥ junto a su gabinete medidas p...   \n",
      "3  Frigerio analiz√≥ junto a su gabinete medidas p...   \n",
      "4  Frigerio analiz√≥ junto a su gabinete medidas p...   \n",
      "5  Frigerio analiz√≥ junto a su gabinete medidas p...   \n",
      "6  Frigerio analiz√≥ junto a su gabinete medidas p...   \n",
      "7  Frigerio analiz√≥ junto a su gabinete medidas p...   \n",
      "8  Frigerio analiz√≥ junto a su gabinete medidas p...   \n",
      "9  Frigerio analiz√≥ junto a su gabinete medidas p...   \n",
      "\n",
      "                                             oracion localidadMasNombrada  \\\n",
      "0  El gobernador Rogerio Frigerio encabez√≥ este v...                  NaN   \n",
      "1  Tras el encuentro, que se desarroll√≥ en Casa d...                  NaN   \n",
      "2  En esa l√≠nea, indic√≥ que uno de los temas de a...                  NaN   \n",
      "3  Tambi√©n mencion√≥ que dialogaron sobre el traba...                  NaN   \n",
      "4  \"Es un programa que ya comenz√≥ en el verano y ...                  NaN   \n",
      "5  \"Se trata de una serie de acciones que tienen ...                  NaN   \n",
      "6  En ese sentido, se refiri√≥ al trabajo que se e...                  NaN   \n",
      "7  \"Se va a capacitar al personal, fundamentalmen...                  NaN   \n",
      "8  Finalmente, Maneiro remarc√≥ que el gobernador ...                  NaN   \n",
      "9  Acompa√±ando el enorme esfuerzo que hacen los e...                  NaN   \n",
      "\n",
      "  intendenteMasNombrado  \n",
      "0                   NaN  \n",
      "1                   NaN  \n",
      "2                   NaN  \n",
      "3                   NaN  \n",
      "4                   NaN  \n",
      "5                   NaN  \n",
      "6                   NaN  \n",
      "7                   NaN  \n",
      "8                   NaN  \n",
      "9                   NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def segmentar_oraciones(texto):\n",
    "    if pd.isnull(texto): return []\n",
    "    # Separa por punto, signo de exclamaci√≥n o interrogaci√≥n\n",
    "    return [s.strip() for s in re.split(r'(?<=[.!?])\\s+', str(texto)) if s.strip()]\n",
    "\n",
    "menciones = []\n",
    "for idx, row in noticias.iterrows():\n",
    "    oraciones = segmentar_oraciones(row['contenido'])\n",
    "    for oracion in oraciones:\n",
    "        menciones.append({\n",
    "            'id_noticia': row['id_nuevo'] if 'id_nuevo' in row else row['id'],\n",
    "            'medio': row['medio'],\n",
    "            'fecha': row['fecha'],\n",
    "            'titulo': row['titulo'],\n",
    "            'oracion': oracion,\n",
    "            'localidadMasNombrada': row.get('localidadMasNombrada', np.nan),\n",
    "            'intendenteMasNombrado': row.get('intendenteMasNombrado', np.nan),\n",
    "        })\n",
    "\n",
    "df_menciones = pd.DataFrame(menciones)\n",
    "print(f\"üìù Total de menciones (oraciones): {len(df_menciones)}\")\n",
    "print(df_menciones.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6552c841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Noticias a clasificar (con intendente): 583\n",
      "üîé Menciones a clasificar (con intendente): 11610\n",
      "\n",
      "--- Resumen de sentimiento por noticia ---\n",
      "sentimiento_noticia                     NEG  NEU  POS\n",
      "intendenteMasNombrado                                \n",
      "Claudia Monjo                             1    4    0\n",
      "Dora Bogdan                               0    2    3\n",
      "Francisco Azcu√©                          28   30   11\n",
      "Jos√© Eduardo Lauritto                     8    6    3\n",
      "Mauricio Davico                           7   10    8\n",
      "Rosario Romero                           31  170  249\n",
      "Rosario Romero / Jos√© Eduardo Lauritto    1    9    2\n",
      "\n",
      "--- Resumen de sentimiento por menci√≥n (oraci√≥n) ---\n",
      "sentimiento_mencion                      NEG   NEU   POS\n",
      "intendenteMasNombrado                                   \n",
      "Claudia Monjo                             14    65    13\n",
      "Dora Bogdan                               11    43    26\n",
      "Francisco Azcu√©                          394   636   280\n",
      "Jos√© Eduardo Lauritto                     98   178    72\n",
      "Mauricio Davico                          114   266   130\n",
      "Rosario Romero                          1079  4392  3532\n",
      "Rosario Romero / Jos√© Eduardo Lauritto    43   130    94\n",
      "‚úÖ Exportado: noticias_etiquetadas.csv\n",
      "‚úÖ Exportado: menciones_etiquetadas.csv\n",
      "‚úÖ Exportado: resumen_noticias.csv\n",
      "‚úÖ Exportado: resumen_menciones.csv\n",
      "‚úÖ Exportado: muestra_100_menciones.csv\n"
     ]
    }
   ],
   "source": [
    "import pysentimiento\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. Filtrar solo con intendente etiquetado ---\n",
    "noticias_intendente = noticias[noticias['intendenteMasNombrado'].notna()].copy()\n",
    "print(f\"üîé Noticias a clasificar (con intendente): {len(noticias_intendente)}\")\n",
    "\n",
    "menciones_intendente = df_menciones[df_menciones['intendenteMasNombrado'].notna()].copy()\n",
    "print(f\"üîé Menciones a clasificar (con intendente): {len(menciones_intendente)}\")\n",
    "\n",
    "# --- 2. An√°lisis de sentimiento ---\n",
    "analyzer = pysentimiento.create_analyzer(task=\"sentiment\", lang=\"es\")\n",
    "\n",
    "def sentimiento_noticia(texto):\n",
    "    resultado = analyzer.predict(str(texto))\n",
    "    return pd.Series({\n",
    "        'sentimiento_noticia': resultado.output,\n",
    "        'proba_sentimiento_noticia': float(resultado.probas[resultado.output])\n",
    "    })\n",
    "\n",
    "def sentimiento_mencion(texto):\n",
    "    resultado = analyzer.predict(str(texto))\n",
    "    return pd.Series({\n",
    "        'sentimiento_mencion': resultado.output,\n",
    "        'proba_sentimiento_mencion': float(resultado.probas[resultado.output])\n",
    "    })\n",
    "\n",
    "# Aplicar en bloque\n",
    "noticias_intendente[['sentimiento_noticia', 'proba_sentimiento_noticia']] = (\n",
    "    noticias_intendente['contenido'].apply(sentimiento_noticia)\n",
    ")\n",
    "menciones_intendente[['sentimiento_mencion', 'proba_sentimiento_mencion']] = (\n",
    "    menciones_intendente['oracion'].apply(sentimiento_mencion)\n",
    ")\n",
    "\n",
    "# --- 3. Tablas resumen ---\n",
    "print(\"\\n--- Resumen de sentimiento por noticia ---\")\n",
    "resumen_noticias = (\n",
    "    noticias_intendente\n",
    "    .groupby(['intendenteMasNombrado', 'sentimiento_noticia'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .sort_index()\n",
    ")\n",
    "print(resumen_noticias)\n",
    "\n",
    "print(\"\\n--- Resumen de sentimiento por menci√≥n (oraci√≥n) ---\")\n",
    "resumen_menciones = (\n",
    "    menciones_intendente\n",
    "    .groupby(['intendenteMasNombrado', 'sentimiento_mencion'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .sort_index()\n",
    ")\n",
    "print(resumen_menciones)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "OUTPUT_PATH = r\"C:/Users/Lenovo/Documents/github/seguimiento-de-noticias/data/processed\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# 1. Noticias limpias\n",
    "noticias_etiquetadas = noticias.copy()\n",
    "noticias_etiquetadas.to_csv(os.path.join(OUTPUT_PATH, \"noticias_etiquetadas.csv\"), index=False)\n",
    "print(\"‚úÖ Exportado: noticias_etiquetadas.csv\")\n",
    "    \n",
    "# 2. Menciones (oraciones)\n",
    "df_menciones.to_csv(os.path.join(OUTPUT_PATH, \"menciones_etiquetadas.csv\"), index=False)\n",
    "print(\"‚úÖ Exportado: menciones_etiquetadas.csv\")\n",
    "\n",
    "# 3. Resumen por noticia\n",
    "resumen_noticias.to_csv(os.path.join(OUTPUT_PATH, \"resumen_noticias.csv\"))\n",
    "print(\"‚úÖ Exportado: resumen_noticias.csv\")\n",
    "\n",
    "# 4. Resumen por menci√≥n\n",
    "resumen_menciones.to_csv(os.path.join(OUTPUT_PATH, \"resumen_menciones.csv\"))\n",
    "print(\"‚úÖ Exportado: resumen_menciones.csv\")\n",
    "\n",
    "# 5. Muestra aleatoria de 100 menciones para control manual\n",
    "muestra = df_menciones.sample(n=100, random_state=42) if len(df_menciones) >= 100 else df_menciones\n",
    "muestra.to_csv(os.path.join(OUTPUT_PATH, \"muestra_100_menciones.csv\"), index=False)\n",
    "print(\"‚úÖ Exportado: muestra_100_menciones.csv\")\n",
    "\n",
    "# 6. Noticias y menciones con etiquetas \n",
    "noticias_intendente.to_csv(os.path.join(OUTPUT_PATH, \"noticias_intendente_sentimiento.csv\"), index=False)\n",
    "menciones_intendente.to_csv(os.path.join(OUTPUT_PATH, \"menciones_intendente_sentimiento.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f225ca57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_noticia', 'medio', 'fecha', 'titulo', 'oracion',\n",
       "       'localidadMasNombrada', 'intendenteMasNombrado', 'sentimiento_mencion',\n",
       "       'proba_sentimiento_mencion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias_intendente\n",
    "menciones_intendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c017eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
